"""
Predict vulnerability severity using the BERT model directly.
"""

import argparse
import logging
import sys
import os
import json
import torch
from transformers import AutoTokenizer, AutoModelForSequenceClassification

# Configure logging
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(sys.stdout)
    ]
)

logger = logging.getLogger(__name__)

# Severity levels mapping
SEVERITY_LEVELS = ['Low', 'Medium', 'High', 'Critical']

def parse_args():
    """Parse command line arguments."""
    parser = argparse.ArgumentParser(description="Predict severity with BERT model")
    parser.add_argument('--model-dir', default='models/severity_bert/bert_model', 
                        help='Directory containing BERT model')
    parser.add_argument('--description', required=True, help='Vulnerability description to analyze')
    parser.add_argument('--output-file', help='File to save prediction results')
    parser.add_argument('--verbose', '-v', action='store_true', help='Verbose output')
    return parser.parse_args()

def predict_severity(model_dir, description):
    """
    Predict severity for a vulnerability description using BERT model.
    
    Args:
        model_dir: Path to BERT model directory
        description: Vulnerability description text
    
    Returns:
        Predicted severity level
    """
    # Check if model exists
    if not os.path.exists(model_dir) or not os.path.isdir(model_dir):
        logger.error(f"Model directory not found: {model_dir}")
        return None
    
    try:
        # Load tokenizer and model
        tokenizer = AutoTokenizer.from_pretrained(model_dir)
        model = AutoModelForSequenceClassification.from_pretrained(model_dir)
        
        # Set model to evaluation mode
        model.eval()
        
        # Tokenize input
        inputs = tokenizer(
            description,
            padding=True,
            truncation=True,
            max_length=512,
            return_tensors="pt"
        )
        
        # Ensure tensors are on the right device
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        model = model.to(device)
        inputs = {k: v.to(device) for k, v in inputs.items()}
        
        # Make prediction
        with torch.no_grad():
            outputs = model(**inputs)
            predictions = torch.argmax(outputs.logits, dim=-1)
        
        # Convert to severity level
        severity_level = SEVERITY_LEVELS[predictions.item()]
        return severity_level
        
    except Exception as e:
        logger.error(f"Error making prediction: {e}")
        return None

def main():
    """Predict severity using BERT model."""
    args = parse_args()
    
    # Set logging level based on verbosity
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
        
    # Make prediction
    logger.info(f"Using BERT model from: {args.model_dir}")
    logger.info(f"Description: {args.description}")
    
    severity = predict_severity(args.model_dir, args.description)
    
    if severity:
        logger.info(f"Predicted severity: {severity}")
        
        # Save to output file if requested
        if args.output_file:
            with open(args.output_file, 'w') as f:
                json.dump({
                    "severity": severity, 
                    "description": args.description
                }, f, indent=2)
            logger.info(f"Saved prediction to {args.output_file}")
    else:
        logger.error("Failed to make prediction")
        return 1
        
    return 0

if __name__ == "__main__":
    sys.exit(main())
