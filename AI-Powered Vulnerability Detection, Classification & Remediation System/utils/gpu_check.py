"""
Utility to check GPU availability and optimize settings for ML training.
"""
import logging
import sys
import os

logger = logging.getLogger(__name__)

def check_gpu():
    """
    Check if GPU is available for training and optimize settings.
    
    Returns:
        dict: Information about GPU availability and settings
    """
    gpu_info = {
        "available": False,
        "device_name": "CPU",
        "optimized": False,
        "cuda_version": None,
        "pytorch_using_cuda": False
    }
    
    # Check for CUDA
    try:
        import torch
        gpu_info["pytorch_using_cuda"] = torch.cuda.is_available()
        
        if torch.cuda.is_available():
            gpu_info["available"] = True
            gpu_info["device_name"] = torch.cuda.get_device_name(0)
            gpu_info["cuda_version"] = torch.version.cuda
            
            # Set PyTorch to use the GPU
            torch.cuda.set_device(0)
            
            # Optimize memory allocation
            os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'max_split_size_mb:128'
            gpu_info["optimized"] = True
            
            logger.info(f"GPU available: {gpu_info['device_name']}")
            logger.info(f"CUDA Version: {gpu_info['cuda_version']}")
        else:
            logger.warning("No GPU available. Training will use CPU (slower).")
    except ImportError:
        logger.warning("PyTorch not installed. Cannot check GPU availability.")
    
    # Check for cuML (RAPIDS)
    try:
        import cuml
        gpu_info["cuml_available"] = True
        logger.info("cuML (RAPIDS) available for GPU-accelerated ML algorithms")
    except ImportError:
        gpu_info["cuml_available"] = False
        logger.info("cuML not available. Standard sklearn will be used.")
    
    return gpu_info

def optimize_for_gpu_training():
    """
    Apply optimizations for GPU training.
    """
    gpu_info = check_gpu()
    
    if not gpu_info["available"]:
        return False
    
    # Set environment variables for better GPU performance
    os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'  # For TensorFlow
    
    # Try to enable TF32 for better performance on Ampere GPUs
    try:
        import torch
        if torch.cuda.is_available():
            # Enable TF32 for faster computation (A100, RTX 30xx)
            torch.backends.cuda.matmul.allow_tf32 = True
            torch.backends.cudnn.allow_tf32 = True
            
            # Enable cuDNN benchmarking for better performance
            torch.backends.cudnn.benchmark = True
            
            logger.info("Applied GPU optimizations for PyTorch")
    except Exception as e:
        logger.warning(f"Could not apply all GPU optimizations: {e}")
    
    return True

if __name__ == "__main__":
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format="%(asctime)s [%(levelname)s] %(message)s"
    )
    
    # Run the GPU check
    gpu_info = check_gpu()
    
    # Print detailed information
    print("\nGPU Information:")
    print("-" * 40)
    for key, value in gpu_info.items():
        print(f"{key.replace('_', ' ').title()}: {value}")
    print("-" * 40)
    
    if gpu_info["available"]:
        print("\nGPU is available for training!")
        optimize_for_gpu_training()
    else:
        print("\nNo GPU available. Training will use CPU.")
